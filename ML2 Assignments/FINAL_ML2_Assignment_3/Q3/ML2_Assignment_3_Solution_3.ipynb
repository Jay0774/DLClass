{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2_Assignment_3_Solution_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twg8KBSF3BU5",
        "outputId": "a8bcb996-c272-40d9-8633-b8cda80a50f3"
      },
      "source": [
        "!pip install torchtext==0.6.0\n",
        "!wget https://www.cl.uni-heidelberg.de/statnlpgroup/decoco/ms_coco_parallel.tar.bz2\n",
        "!gunzip *.bz2\n",
        "!bunzip2 ms_coco_parallel.tar.bz2\n",
        "!tar -xvf *.tar\n",
        "%cd ms_coco_parallel/\n",
        "\n",
        "\n",
        "# !cat dev.en devtest.en test.en > en_data.txt\n",
        "# !cat dev.de devtest.de test.de > de_data.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n",
            "--2021-01-22 17:25:16--  https://www.cl.uni-heidelberg.de/statnlpgroup/decoco/ms_coco_parallel.tar.bz2\n",
            "Resolving www.cl.uni-heidelberg.de (www.cl.uni-heidelberg.de)... 147.142.207.78\n",
            "Connecting to www.cl.uni-heidelberg.de (www.cl.uni-heidelberg.de)|147.142.207.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31702 (31K) [application/x-bzip2]\n",
            "Saving to: ‘ms_coco_parallel.tar.bz2’\n",
            "\n",
            "ms_coco_parallel.ta 100%[===================>]  30.96K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-01-22 17:25:17 (220 KB/s) - ‘ms_coco_parallel.tar.bz2’ saved [31702/31702]\n",
            "\n",
            "gzip: ms_coco_parallel.tar.bz2: unknown suffix -- ignored\n",
            "ms_coco_parallel/\n",
            "ms_coco_parallel/devtest.de\n",
            "ms_coco_parallel/terms_of_use.txt\n",
            "ms_coco_parallel/devtest.en\n",
            "ms_coco_parallel/dev.en\n",
            "ms_coco_parallel/README.txt\n",
            "ms_coco_parallel/dev.de\n",
            "ms_coco_parallel/test.en\n",
            "ms_coco_parallel/test.de\n",
            "/content/ms_coco_parallel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Vh_KlC3WvP",
        "outputId": "5884150a-6447-4c23-c9b3-15d725c574ed"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.de\tdevtest.de  README.txt\t      test.de\n",
            "dev.en\tdevtest.en  terms_of_use.txt  test.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpwwDqgt3d45"
      },
      "source": [
        "list_train_de=[]\n",
        "filepath=\"dev.de\"\n",
        "with open(filepath, encoding=\"utf8\") as fp:  \n",
        "   for line in fp:\n",
        "       list_train_de.extend(line.strip().split(', '))\n",
        "\n",
        "list_train_en=[]\n",
        "filepath=\"dev.en\"\n",
        "with open(filepath, encoding=\"utf8\") as fp:  \n",
        "   for line in fp:\n",
        "       list_train_en.extend(line.strip().split(', '))\n",
        "\n",
        "list_test_de=[]\n",
        "filepath=\"test.de\"\n",
        "with open(filepath, encoding=\"utf8\") as fp:  \n",
        "   for line in fp:\n",
        "       list_test_de.extend(line.strip().split(', '))\n",
        "\n",
        "list_test_en=[]\n",
        "filepath=\"test.en\"\n",
        "with open(filepath, encoding=\"utf8\") as fp:  \n",
        "   for line in fp:\n",
        "       list_test_en.extend(line.strip().split(', '))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_7oLio756qM"
      },
      "source": [
        "# Lets play with csv and text\n",
        "# try to convert text/arrays to csv and make it our code firendly!!!\n",
        "# Source = English\n",
        "# Target = German / Dutch\n",
        "import pandas as pd\n",
        "train = pd.DataFrame(list(zip(list_train_en, list_train_de)), \n",
        "               columns =['trg', 'src'])\n",
        "\n",
        "test =  pd.DataFrame(list(zip(list_test_en, list_test_de)), \n",
        "               columns =['trg', 'src'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWXpzMQT7oF5",
        "outputId": "c8f6762b-2a7d-493a-f06b-ff5c9ba3a57a"
      },
      "source": [
        "train.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                    trg                                                src\n",
              "0                Giraffes in the forest on a sunny day           Giraffen an einem sonnigen Tag im Busch.\n",
              "1    Zebra and water buffalo walk along the tall gr...  Ein Zebra und ein Wasserbüffel gehen neben hoh...\n",
              "2    The man is only a few inches shorter than his ...  Der Mann ist nur wenige Zoll kleiner als sein ...\n",
              "3                A boy and a dog running down a beach.  Ein Junge und ein Hund rennen einen Strand ent...\n",
              "4    Person with long hair and a fedora standing in...  Eine Person mit langen Haaren und einer Fedora...\n",
              "..                                                 ...                                                ...\n",
              "261  A person holding up a GPS guide showing the sc...  Eine Hand mit einem Wurstbrötchen und einer we...\n",
              "262         A man on a surfboard who is riding a wave.  Eine Gruppe von Leuten mit Regenschirmen nahe ...\n",
              "263        A teddy bear posed sitting in a toy castle.      Auf dem Bus steht bunte Werbung für Pull-Ups.\n",
              "264  a dalmation dog staring at an oven in the kitchen  Zwei Skifahrer fahren eine sehr flache Piste h...\n",
              "265  White vase with flowers sitting on top of the ...                          Ein Teller mit Toastbroot\n",
              "\n",
              "[266 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHyds8oD79Mt",
        "outputId": "ca8f5662-f922-4780-d9aa-247d8a52192f"
      },
      "source": [
        "test.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                    trg                                                src\n",
              "0                A guy does a trick on his skateboard.  Ein Mann führt auf einen Skateboard einen Tric...\n",
              "1         a dog in a field with a frisbee in its mouth  Ein Hund auf einer Wiese mit einem Frisbee im ...\n",
              "2         A bag sitting next to luggage on the ground.  Eine Tasche steht neben anderem Gepäck auf dem...\n",
              "3          A group of people standing around a machine  Eine Gruppe von Leuten steht neben einer Masch...\n",
              "4    An elegant table full of blue arrangements of ...       Ein eleganter Tisch mit vielen blauen Vasen.\n",
              "..                                                 ...                                                ...\n",
              "532  A man with catchers gear on sitting in front o...  Ein Teddybär in einem Hut auf der Straße einer...\n",
              "533  A woman is skiing down a snowy slope with moun...  Zwei Männer spielen ein Computerspiel und eine...\n",
              "534  A tiger striped cat sitting in front of a lapt...  Ein Mann auf einem Skateboard führt einen Tric...\n",
              "535  Dense cabbage plants with some of their \\\"flow...        Ein großer Drache fliegt über einem Strand.\n",
              "536  A group of people walking across snow covered ...  Kinder spielen ein Spiel und Erwachsene schaue...\n",
              "\n",
              "[537 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-9Xvrjy8Da8"
      },
      "source": [
        "\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3_N2ajE_Ihn",
        "outputId": "c88952ba-3519-4cc7-cb44-5977f759399d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.de\tdevtest.de  README.txt\t      test.csv\ttest.en\n",
            "dev.en\tdevtest.en  terms_of_use.txt  test.de\ttrain.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywCRUWmJ_Jm6",
        "outputId": "15c0da3c-e292-4594-e6fc-8498fdf9c857"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
        "import pandas as pd\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de\n",
        "\n",
        "\n",
        "spacy_eng = spacy.load(\"en\")\n",
        "spacy_ger = spacy.load(\"de\")\n",
        "\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "\n",
        "def tokenize_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "\n",
        "english = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, lower=True)\n",
        "german = Field(sequential=True, use_vocab=True, tokenize=tokenize_ger, lower=True)\n",
        "\n",
        "fields = {\"trg\": (\"trg\", english), \"src\": (\"src\", german)}\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "    path=\"\", train=\"train.csv\", test=\"test.csv\", format=\"csv\", fields=fields\n",
        ")\n",
        "\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data), batch_size=32, device=\"cuda\"\n",
        ")\n",
        "\n",
        "for batch in train_iterator:\n",
        "    print(batch)\n",
        "\n",
        "# string to integer (stoi)\n",
        "print(f'Index of the word (the) is: {english.vocab.stoi[\"the\"]}')\n",
        "\n",
        "# print integer to string (itos)\n",
        "print(f\"Word of the index (16) is: {english.vocab.itos[16]}\")\n",
        "print(f\"Word of the index (17) is: {english.vocab.itos[17]}\")\n",
        "print(f\"Word of the index (18) is: {english.vocab.itos[18]}\")\n",
        "print(f\"Word of the index (19) is: {english.vocab.itos[19]}\")\n",
        "print(f\"Word of the index (20) is: {english.vocab.itos[20]}\")\n",
        "print(f\"Word of the index (21) is: {english.vocab.itos[21]}\")\n",
        "print(f\"Word of the index (0) is: {english.vocab.itos[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=ea5348f691bc65c906b16e435358108c290016ddb00e0a95aeb5d1c0f312d275\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bhsglppz/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "\n",
            "[torchtext.data.batch.Batch of size 10]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 16x10 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 15x10 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 22x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 22x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 21x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 21x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 15x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 17x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 21x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 17x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 17x32 (GPU 0)]\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 18x32 (GPU 0)]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "Index of the word (the) is: 6\n",
            "Word of the index (16) is: are\n",
            "Word of the index (17) is: next\n",
            "Word of the index (18) is: two\n",
            "Word of the index (19) is: sitting\n",
            "Word of the index (20) is: holding\n",
            "Word of the index (21) is: front\n",
            "Word of the index (0) is: <unk>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eCArk5iO3mJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44b1547-694d-4a41-c81f-c66da9094a04"
      },
      "source": [
        "!pip install torchtext==0.6.0\r\n",
        "import torch\r\n",
        "from torchtext.data.metrics import bleu_score\r\n",
        "import spacy\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\r\n",
        "    # Load german tokenizer\r\n",
        "    spacy_ger = spacy.load(\"de\")\r\n",
        "\r\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\r\n",
        "    if type(sentence) == str:\r\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\r\n",
        "    tokens.insert(0, german.init_token)\r\n",
        "    tokens.append(german.eos_token)\r\n",
        "\r\n",
        "    # Go through each german token and convert to an index\r\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    # Convert to Tensor\r\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\r\n",
        "    for i in range(max_length):\r\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            output = model(sentence_tensor, trg_tensor)\r\n",
        "\r\n",
        "        best_guess = output.argmax(2)[-1, :].item()\r\n",
        "        outputs.append(best_guess)\r\n",
        "\r\n",
        "        if best_guess == english.vocab.stoi[\"<eos>\"]:\r\n",
        "            break\r\n",
        "\r\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\r\n",
        "    # remove start token\r\n",
        "    return translated_sentence[1:]\r\n",
        "\r\n",
        "def bleu(data, model, german, english, device):\r\n",
        "    targets= []\r\n",
        "    outputs= []\r\n",
        "\r\n",
        "    for eg in data:\r\n",
        "        src = vars(eg)['src']\r\n",
        "        trg = vars(eg)['trg']\r\n",
        "\r\n",
        "        prediction = translate_sentence(model, src, german, english, device)\r\n",
        "        prediction = prediction[:-1] # eos removed\r\n",
        "\r\n",
        "        targets.append([trg])\r\n",
        "        outputs.append(prediction)\r\n",
        "\r\n",
        "    return bleu_score(outputs, targets)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XspuDEACEqV"
      },
      "source": [
        "# Senetence : Giraffen an einem sonnigen Tag im Busch.\n",
        "# Converted Expected : Giraffes in the forest on a sunny day"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PetRRgyYCKe4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH1XXaTqOi9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ba8cc1-ab86-4a0b-ae4a-dce23eb2ff6c"
      },
      "source": [
        "\r\n",
        "class Transformer(nn.Module):\r\n",
        "    def __init__(self,\r\n",
        "                embedding_size,\r\n",
        "                src_vocab_size,\r\n",
        "                trg_vocab_size,\r\n",
        "                src_pad_idx,\r\n",
        "                num_heads,\r\n",
        "                num_encoder_layers,\r\n",
        "                num_decoder_layers,\r\n",
        "                forward_expansion,\r\n",
        "                dropout,\r\n",
        "                max_len,\r\n",
        "                device\r\n",
        "    ):\r\n",
        "        super(Transformer,self).__init__()\r\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size,embedding_size)\r\n",
        "        self.src_positional_embedding = nn.Embedding(max_len,embedding_size)\r\n",
        "        self.trg_word_embedding =  nn.Embedding(trg_vocab_size,embedding_size)\r\n",
        "        self.trg_positional_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "\r\n",
        "        self.device = device\r\n",
        "        self.transformer = nn.Transformer(\r\n",
        "                    embedding_size,\r\n",
        "                    num_heads,\r\n",
        "                    num_encoder_layers,\r\n",
        "                    num_decoder_layers,\r\n",
        "                    forward_expansion,\r\n",
        "                    dropout\r\n",
        "        )\r\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        self.src_pad_idx = src_pad_idx\r\n",
        "\r\n",
        "    def make_src_masks(self,src):\r\n",
        "        # src : (src_len, bs)\r\n",
        "        src_mask = src.transpose(0,1) == self.src_pad_idx\r\n",
        "        # (bs, src_len)\r\n",
        "        return src_mask\r\n",
        "\r\n",
        "    def forward(self, src, trg):\r\n",
        "        src_seq_len , N = src.shape\r\n",
        "        trg_seq_len , N = trg.shape\r\n",
        "\r\n",
        "        src_positions =(\r\n",
        "            torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, N).to(self.device)\r\n",
        "        )\r\n",
        "        trg_positions = (\r\n",
        "            torch.arange(0, trg_seq_len).unsqueeze(1).expand(trg_seq_len, N).to(self.device)\r\n",
        "        )\r\n",
        "\r\n",
        "        embed_src = self.dropout(\r\n",
        "            (self.src_word_embedding(src) + self.src_positional_embedding(src_positions))\r\n",
        "        )\r\n",
        "        embed_trg = self.dropout(\r\n",
        "            (self.trg_word_embedding(trg) + self.trg_positional_embedding(trg_positions))\r\n",
        "        )\r\n",
        "        src_padding_mask = self.make_src_masks(src)\r\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_len).to(self.device)\r\n",
        "\r\n",
        "        out = self.transformer(embed_src, embed_trg, src_key_padding_mask=src_padding_mask,tgt_mask=trg_mask)\r\n",
        "\r\n",
        "        out = self.fc_out(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "#\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "load_model =True\r\n",
        "save_model = False\r\n",
        "\r\n",
        "#training hyperparameters\r\n",
        "num_epochs = 100\r\n",
        "learning_rate = 3e-4\r\n",
        "batch_size= 32\r\n",
        "\r\n",
        "#model hyperparameters\r\n",
        "src_vocab_size = len(german.vocab)\r\n",
        "trg_vocab_size = len(english.vocab)\r\n",
        "embedding_size = 512\r\n",
        "num_heads = 8\r\n",
        "num_encoder_layers = 3\r\n",
        "num_decoder_layers = 3\r\n",
        "dropout = 0.1\r\n",
        "max_len = 100\r\n",
        "forward_expansion = 4\r\n",
        "src_pad_idx = english.vocab.stoi['<pad>']\r\n",
        "\r\n",
        "writer = SummaryWriter(\"runs/loss_plot\")\r\n",
        "step = 0\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "        (train_data, validation_data, test_data),\r\n",
        "        batch_size = batch_size,\r\n",
        "        sort_within_batch=True,\r\n",
        "        sort_key = lambda x: len(x.src),\r\n",
        "        device = device)\r\n",
        "\r\n",
        "model = Transformer(embedding_size,\r\n",
        "            src_vocab_size,\r\n",
        "            trg_vocab_size,\r\n",
        "            src_pad_idx,\r\n",
        "            num_heads,\r\n",
        "            num_encoder_layers,\r\n",
        "            num_decoder_layers,\r\n",
        "            forward_expansion,\r\n",
        "            dropout,\r\n",
        "            max_len,\r\n",
        "            device).to(device)\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\r\n",
        "\r\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\r\n",
        "\r\n",
        "'''if load_model:\r\n",
        "    load_checkpoint(torch.load('my_checkpoint.pth.tar',map_location=torch.device('cpu')), model, optimizer)\r\n",
        "    print(\"Loaded\")'''\r\n",
        "\r\n",
        "train = True\r\n",
        "if train:\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        print(f'[Epoch{epoch+1}/{num_epochs}]')\r\n",
        "\r\n",
        "        if save_model:\r\n",
        "            checkpoint= {\r\n",
        "            \"state_dict\" : model.state_dict(),\r\n",
        "            \"optimizer\" : optimizer.state_dict(),\r\n",
        "            }\r\n",
        "        #save_checkpoint(checkpoint)\r\n",
        "\r\n",
        "        for batch_idx,batch in enumerate(train_iterator):\r\n",
        "            inp_data = batch.src.to(device)\r\n",
        "            target = batch.trg.to(device)\r\n",
        "\r\n",
        "            #forward prop\r\n",
        "            output = model(inp_data, target[:-1])\r\n",
        "\r\n",
        "            output = output.reshape(-1,output.shape[2])\r\n",
        "            target = target[1:].reshape(-1)\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            loss = criterion(output, target)\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm =1)\r\n",
        "\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            writer.add_scalar(\"Training loss\", loss, global_step=step)\r\n",
        "            step+=1\r\n",
        "sen1 = \"Giraffen an einem sonnigen Tag im Busch.\"\r\n",
        "\r\n",
        "a = translate_sentence(model, sen1, german,english, device, max_length=30)\r\n",
        "\r\n",
        "print(\"English\")\r\n",
        "print(a)\r\n",
        "\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.argv=['']\r\n",
        "del sys\r\n",
        "\r\n",
        "score = bleu(test_data[1:150],model,german,english,device)\r\n",
        "print(\"score:\")\r\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=146ba67e58986f3bdd0ea310c14a9262ec7ecd9bb7235f88ec13df13a4bc1fd6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qv2be5wf/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 965kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 277kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 265kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch1/100]\n",
            "[Epoch2/100]\n",
            "[Epoch3/100]\n",
            "[Epoch4/100]\n",
            "[Epoch5/100]\n",
            "[Epoch6/100]\n",
            "[Epoch7/100]\n",
            "[Epoch8/100]\n",
            "[Epoch9/100]\n",
            "[Epoch10/100]\n",
            "[Epoch11/100]\n",
            "[Epoch12/100]\n",
            "[Epoch13/100]\n",
            "[Epoch14/100]\n",
            "[Epoch15/100]\n",
            "[Epoch16/100]\n",
            "[Epoch17/100]\n",
            "[Epoch18/100]\n",
            "[Epoch19/100]\n",
            "[Epoch20/100]\n",
            "[Epoch21/100]\n",
            "[Epoch22/100]\n",
            "[Epoch23/100]\n",
            "[Epoch24/100]\n",
            "[Epoch25/100]\n",
            "[Epoch26/100]\n",
            "[Epoch27/100]\n",
            "[Epoch28/100]\n",
            "[Epoch29/100]\n",
            "[Epoch30/100]\n",
            "[Epoch31/100]\n",
            "[Epoch32/100]\n",
            "[Epoch33/100]\n",
            "[Epoch34/100]\n",
            "[Epoch35/100]\n",
            "[Epoch36/100]\n",
            "[Epoch37/100]\n",
            "[Epoch38/100]\n",
            "[Epoch39/100]\n",
            "[Epoch40/100]\n",
            "[Epoch41/100]\n",
            "[Epoch42/100]\n",
            "[Epoch43/100]\n",
            "[Epoch44/100]\n",
            "[Epoch45/100]\n",
            "[Epoch46/100]\n",
            "[Epoch47/100]\n",
            "[Epoch48/100]\n",
            "[Epoch49/100]\n",
            "[Epoch50/100]\n",
            "[Epoch51/100]\n",
            "[Epoch52/100]\n",
            "[Epoch53/100]\n",
            "[Epoch54/100]\n",
            "[Epoch55/100]\n",
            "[Epoch56/100]\n",
            "[Epoch57/100]\n",
            "[Epoch58/100]\n",
            "[Epoch59/100]\n",
            "[Epoch60/100]\n",
            "[Epoch61/100]\n",
            "[Epoch62/100]\n",
            "[Epoch63/100]\n",
            "[Epoch64/100]\n",
            "[Epoch65/100]\n",
            "[Epoch66/100]\n",
            "[Epoch67/100]\n",
            "[Epoch68/100]\n",
            "[Epoch69/100]\n",
            "[Epoch70/100]\n",
            "[Epoch71/100]\n",
            "[Epoch72/100]\n",
            "[Epoch73/100]\n",
            "[Epoch74/100]\n",
            "[Epoch75/100]\n",
            "[Epoch76/100]\n",
            "[Epoch77/100]\n",
            "[Epoch78/100]\n",
            "[Epoch79/100]\n",
            "[Epoch80/100]\n",
            "[Epoch81/100]\n",
            "[Epoch82/100]\n",
            "[Epoch83/100]\n",
            "[Epoch84/100]\n",
            "[Epoch85/100]\n",
            "[Epoch86/100]\n",
            "[Epoch87/100]\n",
            "[Epoch88/100]\n",
            "[Epoch89/100]\n",
            "[Epoch90/100]\n",
            "[Epoch91/100]\n",
            "[Epoch92/100]\n",
            "[Epoch93/100]\n",
            "[Epoch94/100]\n",
            "[Epoch95/100]\n",
            "[Epoch96/100]\n",
            "[Epoch97/100]\n",
            "[Epoch98/100]\n",
            "[Epoch99/100]\n",
            "[Epoch100/100]\n",
            "English\n",
            "['the', '<unk>', 'on', 'a', 'sunny', 'day', 'in', 'the', '<unk>', '.', '<eos>']\n",
            "score:\n",
            "0.3256714642047882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUl86b1eTIi1",
        "outputId": "69078593-2f5a-4f59-f4c1-ebd69b7f4be2"
      },
      "source": [
        "sen1 = \"Alle die wandern sind nicht verloren\"\n",
        "# English Original: All those who wander are not lost\n",
        "a = translate_sentence(model, sen1, german,english, device, max_length=30)\n",
        "\n",
        "print(\"English\")\n",
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English\n",
            "['all', 'the', 'back', 'of', 'the', 'skate', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}