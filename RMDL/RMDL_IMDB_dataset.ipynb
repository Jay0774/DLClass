{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RMDL IMDB dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392UZfY1MlP0",
        "outputId": "afc6ce66-3dd2-4107-8e16-8144444b0d50"
      },
      "source": [
        "!pip install RMDL"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting RMDL\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/1c/7911d9b8ea3a95983d19720560963b3b809af7308a46a111756606ed928f/RMDL-1.0.8-py2.py3-none-any.whl (44kB)\n",
            "\r\u001b[K     |███████▍                        | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 20kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 30kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from RMDL) (3.2.2)\n",
            "Requirement already satisfied: keras>=2.0.9 in /usr/local/lib/python3.6/dist-packages (from RMDL) (2.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from RMDL) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from RMDL) (1.4.1)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.6/dist-packages (from RMDL) (3.2.5)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from RMDL) (1.1.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from RMDL) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from RMDL) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->RMDL) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->RMDL) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->RMDL) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->RMDL) (2.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.9->RMDL) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.9->RMDL) (3.13)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.0->RMDL) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.4->RMDL) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->RMDL) (2018.9)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (2.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (1.32.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->RMDL) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow->RMDL) (53.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->RMDL) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->RMDL) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->RMDL) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->RMDL) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->RMDL) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->RMDL) (1.25.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->RMDL) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->RMDL) (3.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->RMDL) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->RMDL) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->RMDL) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->RMDL) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->RMDL) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->RMDL) (4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->RMDL) (4.2.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->RMDL) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->RMDL) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->RMDL) (0.4.8)\n",
            "Installing collected packages: RMDL\n",
            "Successfully installed RMDL-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-5GGxWyMrnH",
        "outputId": "63de8b9e-f830-4e31-e8a9-8650122c1783"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from RMDL import text_feature_extraction as txt\n",
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from RMDL import RMDL_Text as RMDL"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yneEkcgZMxvI",
        "outputId": "94efbe59-09da-40c9-acac-d97a6c304a58"
      },
      "source": [
        "print(\"Load IMDB dataset....\")\n",
        "MAX_NB_WORDS = 7500\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=MAX_NB_WORDS)\n",
        "print(len(X_train))\n",
        "print(y_test)\n",
        "word_index = imdb.get_word_index()\n",
        "index_word = {v: k for k, v in word_index.items()}\n",
        "X_train = [txt.text_cleaner(' '.join(index_word.get(w) for w in x)) for x in X_train]\n",
        "X_test = [txt.text_cleaner(' '.join(index_word.get(w) for w in x)) for x in X_test]\n",
        "X_train = np.array(X_train)\n",
        "X_train = np.array(X_train).ravel()\n",
        "print(X_train.shape)\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.array(X_test).ravel()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load IMDB dataset....\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "[0 1 1 ... 0 0 0]\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJvykUg-My4s",
        "outputId": "51ada774-8793-4a73-d3ab-92e11984075a"
      },
      "source": [
        "batch_size = 100\n",
        "sparse_categorical = 0\n",
        "n_epochs = [50, 50, 50]  ## DNN--RNN-CNN\n",
        "Random_Deep = [2, 2, 2]  ## DNN--RNN-CNN\n",
        "\n",
        "RMDL.Text_Classification(X_train, y_train, X_test, y_test,\n",
        "                     batch_size=batch_size,\n",
        "                     sparse_categorical=sparse_categorical,\n",
        "                     random_deep=Random_Deep,\n",
        "                     epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done1\n",
            "converted_into_one_hot\n",
            ".\\Glove/glove.6B.zip\n",
            "tf-idf with 7335 features\n",
            "/content/.\\Glove/glove.6B.50d.txt\n",
            "Found 7497 unique tokens.\n",
            "(50000, 500)\n",
            "Total 400000 word vectors.\n",
            "2\n",
            "DNN 0\n",
            "<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4946622e10>\n",
            "Epoch 1/50\n",
            "250/250 - 7s - loss: 0.4446 - accuracy: 0.7784 - val_loss: 0.4512 - val_accuracy: 0.8058\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.80580, saving model to weights\\weights_DNN_0.hdf5\n",
            "Epoch 2/50\n",
            "250/250 - 4s - loss: 0.2725 - accuracy: 0.9052 - val_loss: 0.3254 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.80580 to 0.88336, saving model to weights\\weights_DNN_0.hdf5\n",
            "Epoch 3/50\n",
            "250/250 - 3s - loss: 0.2387 - accuracy: 0.9280 - val_loss: 0.3978 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.88336\n",
            "Epoch 4/50\n",
            "250/250 - 3s - loss: 0.2077 - accuracy: 0.9413 - val_loss: 0.4358 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.88336\n",
            "Epoch 5/50\n",
            "250/250 - 3s - loss: 0.1966 - accuracy: 0.9509 - val_loss: 0.6236 - val_accuracy: 0.8722\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.88336\n",
            "Epoch 6/50\n",
            "250/250 - 3s - loss: 0.1728 - accuracy: 0.9576 - val_loss: 0.9587 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.88336\n",
            "Epoch 7/50\n",
            "250/250 - 3s - loss: 0.1714 - accuracy: 0.9633 - val_loss: 1.1601 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.88336\n",
            "Epoch 8/50\n",
            "250/250 - 3s - loss: 0.1633 - accuracy: 0.9690 - val_loss: 2.7882 - val_accuracy: 0.8658\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.88336\n",
            "Epoch 9/50\n",
            "250/250 - 3s - loss: 0.1300 - accuracy: 0.9735 - val_loss: 3.0272 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.88336\n",
            "Epoch 10/50\n",
            "250/250 - 3s - loss: 0.1163 - accuracy: 0.9739 - val_loss: 4.8521 - val_accuracy: 0.8656\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.88336\n",
            "Epoch 11/50\n",
            "250/250 - 3s - loss: 0.1119 - accuracy: 0.9800 - val_loss: 3.6897 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.88336\n",
            "Epoch 12/50\n",
            "250/250 - 3s - loss: 0.0939 - accuracy: 0.9816 - val_loss: 7.3086 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.88336\n",
            "Epoch 13/50\n",
            "250/250 - 3s - loss: 0.0992 - accuracy: 0.9840 - val_loss: 7.3277 - val_accuracy: 0.8654\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.88336\n",
            "Epoch 14/50\n",
            "250/250 - 3s - loss: 0.1209 - accuracy: 0.9867 - val_loss: 8.4843 - val_accuracy: 0.8583\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.88336\n",
            "Epoch 15/50\n",
            "250/250 - 3s - loss: 0.0550 - accuracy: 0.9880 - val_loss: 14.2338 - val_accuracy: 0.8572\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.88336\n",
            "Epoch 16/50\n",
            "250/250 - 3s - loss: 0.1467 - accuracy: 0.9892 - val_loss: 11.2472 - val_accuracy: 0.8612\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.88336\n",
            "Epoch 17/50\n",
            "250/250 - 3s - loss: 0.1001 - accuracy: 0.9896 - val_loss: 12.3287 - val_accuracy: 0.8675\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.88336\n",
            "Epoch 18/50\n",
            "250/250 - 3s - loss: 0.0897 - accuracy: 0.9905 - val_loss: 9.0497 - val_accuracy: 0.8636\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.88336\n",
            "Epoch 19/50\n",
            "250/250 - 3s - loss: 0.1203 - accuracy: 0.9903 - val_loss: 9.1830 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.88336\n",
            "Epoch 20/50\n",
            "250/250 - 3s - loss: 0.0775 - accuracy: 0.9912 - val_loss: 13.3865 - val_accuracy: 0.8623\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.88336\n",
            "Epoch 21/50\n",
            "250/250 - 3s - loss: 0.1184 - accuracy: 0.9911 - val_loss: 9.6549 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.88336\n",
            "Epoch 22/50\n",
            "250/250 - 3s - loss: 0.1250 - accuracy: 0.9921 - val_loss: 10.0930 - val_accuracy: 0.8642\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.88336\n",
            "Epoch 23/50\n",
            "250/250 - 3s - loss: 0.1073 - accuracy: 0.9921 - val_loss: 9.1909 - val_accuracy: 0.8579\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.88336\n",
            "Epoch 24/50\n",
            "250/250 - 3s - loss: 0.0718 - accuracy: 0.9928 - val_loss: 15.1610 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88336\n",
            "Epoch 25/50\n",
            "250/250 - 3s - loss: 0.1265 - accuracy: 0.9919 - val_loss: 10.8833 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88336\n",
            "Epoch 26/50\n",
            "250/250 - 3s - loss: 0.1751 - accuracy: 0.9922 - val_loss: 9.5396 - val_accuracy: 0.8633\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88336\n",
            "Epoch 27/50\n",
            "250/250 - 3s - loss: 0.1297 - accuracy: 0.9936 - val_loss: 10.2483 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88336\n",
            "Epoch 28/50\n",
            "250/250 - 3s - loss: 0.0914 - accuracy: 0.9930 - val_loss: 10.1423 - val_accuracy: 0.8638\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88336\n",
            "Epoch 29/50\n",
            "250/250 - 3s - loss: 0.1265 - accuracy: 0.9933 - val_loss: 16.5440 - val_accuracy: 0.8573\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88336\n",
            "Epoch 30/50\n",
            "250/250 - 3s - loss: 0.1117 - accuracy: 0.9936 - val_loss: 10.4822 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88336\n",
            "Epoch 31/50\n",
            "250/250 - 3s - loss: 0.0898 - accuracy: 0.9936 - val_loss: 5.8564 - val_accuracy: 0.8589\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88336\n",
            "Epoch 32/50\n",
            "250/250 - 3s - loss: 0.1286 - accuracy: 0.9925 - val_loss: 8.9805 - val_accuracy: 0.8654\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88336\n",
            "Epoch 33/50\n",
            "250/250 - 3s - loss: 0.1943 - accuracy: 0.9937 - val_loss: 7.5442 - val_accuracy: 0.8620\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88336\n",
            "Epoch 34/50\n",
            "250/250 - 3s - loss: 0.1351 - accuracy: 0.9936 - val_loss: 9.9304 - val_accuracy: 0.8556\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88336\n",
            "Epoch 35/50\n",
            "250/250 - 3s - loss: 0.1117 - accuracy: 0.9929 - val_loss: 8.2721 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88336\n",
            "Epoch 36/50\n",
            "250/250 - 3s - loss: 0.1096 - accuracy: 0.9945 - val_loss: 11.7267 - val_accuracy: 0.8636\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88336\n",
            "Epoch 37/50\n",
            "250/250 - 3s - loss: 0.1050 - accuracy: 0.9943 - val_loss: 11.7317 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88336\n",
            "Epoch 38/50\n",
            "250/250 - 3s - loss: 0.0933 - accuracy: 0.9950 - val_loss: 23.1373 - val_accuracy: 0.8623\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88336\n",
            "Epoch 39/50\n",
            "250/250 - 3s - loss: 0.1610 - accuracy: 0.9943 - val_loss: 10.9403 - val_accuracy: 0.8651\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88336\n",
            "Epoch 40/50\n",
            "250/250 - 3s - loss: 0.1054 - accuracy: 0.9940 - val_loss: 10.3665 - val_accuracy: 0.8633\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88336\n",
            "Epoch 41/50\n",
            "250/250 - 4s - loss: 0.0866 - accuracy: 0.9941 - val_loss: 6.2317 - val_accuracy: 0.8651\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88336\n",
            "Epoch 42/50\n",
            "250/250 - 3s - loss: 0.0442 - accuracy: 0.9943 - val_loss: 12.5784 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88336\n",
            "Epoch 43/50\n",
            "250/250 - 3s - loss: 0.2354 - accuracy: 0.9951 - val_loss: 11.9077 - val_accuracy: 0.8617\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88336\n",
            "Epoch 44/50\n",
            "250/250 - 3s - loss: 0.0430 - accuracy: 0.9942 - val_loss: 21.4064 - val_accuracy: 0.8623\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88336\n",
            "Epoch 45/50\n",
            "250/250 - 3s - loss: 0.4127 - accuracy: 0.9927 - val_loss: 10.4330 - val_accuracy: 0.8637\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88336\n",
            "Epoch 46/50\n",
            "250/250 - 3s - loss: 0.1370 - accuracy: 0.9934 - val_loss: 7.8759 - val_accuracy: 0.8616\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88336\n",
            "Epoch 47/50\n",
            "250/250 - 3s - loss: 0.1162 - accuracy: 0.9933 - val_loss: 10.0221 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88336\n",
            "Epoch 48/50\n",
            "250/250 - 3s - loss: 0.1193 - accuracy: 0.9929 - val_loss: 9.8424 - val_accuracy: 0.8590\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88336\n",
            "Epoch 49/50\n",
            "250/250 - 3s - loss: 0.1078 - accuracy: 0.9944 - val_loss: 19.1843 - val_accuracy: 0.8654\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88336\n",
            "Epoch 50/50\n",
            "250/250 - 3s - loss: 0.0818 - accuracy: 0.9937 - val_loss: 16.3963 - val_accuracy: 0.8631\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88336\n",
            "DNN 1\n",
            "<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f493b590e10>\n",
            "Epoch 1/50\n",
            "250/250 - 4s - loss: 0.4114 - accuracy: 0.8094 - val_loss: 0.3079 - val_accuracy: 0.8844\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88444, saving model to weights\\weights_DNN_1.hdf5\n",
            "Epoch 2/50\n",
            "250/250 - 2s - loss: 0.2623 - accuracy: 0.9084 - val_loss: 0.3282 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.88444\n",
            "Epoch 3/50\n",
            "250/250 - 2s - loss: 0.2359 - accuracy: 0.9294 - val_loss: 0.3830 - val_accuracy: 0.8766\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.88444\n",
            "Epoch 4/50\n",
            "250/250 - 2s - loss: 0.2236 - accuracy: 0.9414 - val_loss: 0.4488 - val_accuracy: 0.8644\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.88444\n",
            "Epoch 5/50\n",
            "250/250 - 2s - loss: 0.2126 - accuracy: 0.9508 - val_loss: 0.7793 - val_accuracy: 0.8637\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.88444\n",
            "Epoch 6/50\n",
            "250/250 - 2s - loss: 0.1801 - accuracy: 0.9605 - val_loss: 1.5861 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.88444\n",
            "Epoch 7/50\n",
            "250/250 - 2s - loss: 0.1706 - accuracy: 0.9685 - val_loss: 1.4941 - val_accuracy: 0.8678\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.88444\n",
            "Epoch 8/50\n",
            "250/250 - 2s - loss: 0.1377 - accuracy: 0.9743 - val_loss: 1.4453 - val_accuracy: 0.8663\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.88444\n",
            "Epoch 9/50\n",
            "250/250 - 2s - loss: 0.1257 - accuracy: 0.9801 - val_loss: 3.9481 - val_accuracy: 0.8628\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.88444\n",
            "Epoch 10/50\n",
            "250/250 - 2s - loss: 0.0867 - accuracy: 0.9856 - val_loss: 4.7876 - val_accuracy: 0.8610\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.88444\n",
            "Epoch 11/50\n",
            "250/250 - 2s - loss: 0.1025 - accuracy: 0.9882 - val_loss: 6.0042 - val_accuracy: 0.8605\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.88444\n",
            "Epoch 12/50\n",
            "250/250 - 2s - loss: 0.0884 - accuracy: 0.9909 - val_loss: 9.3732 - val_accuracy: 0.8562\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.88444\n",
            "Epoch 13/50\n",
            "250/250 - 2s - loss: 0.0882 - accuracy: 0.9922 - val_loss: 11.2649 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.88444\n",
            "Epoch 14/50\n",
            "250/250 - 2s - loss: 0.0577 - accuracy: 0.9936 - val_loss: 12.3643 - val_accuracy: 0.8560\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.88444\n",
            "Epoch 15/50\n",
            "250/250 - 2s - loss: 0.0692 - accuracy: 0.9947 - val_loss: 13.1814 - val_accuracy: 0.8466\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.88444\n",
            "Epoch 16/50\n",
            "250/250 - 2s - loss: 0.0410 - accuracy: 0.9960 - val_loss: 19.6687 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.88444\n",
            "Epoch 17/50\n",
            "250/250 - 2s - loss: 0.0585 - accuracy: 0.9961 - val_loss: 20.2045 - val_accuracy: 0.8541\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.88444\n",
            "Epoch 18/50\n",
            "250/250 - 2s - loss: 0.0450 - accuracy: 0.9966 - val_loss: 20.2348 - val_accuracy: 0.8616\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.88444\n",
            "Epoch 19/50\n",
            "250/250 - 2s - loss: 0.0592 - accuracy: 0.9960 - val_loss: 19.8395 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.88444\n",
            "Epoch 20/50\n",
            "250/250 - 2s - loss: 0.0321 - accuracy: 0.9963 - val_loss: 16.2641 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.88444\n",
            "Epoch 21/50\n",
            "250/250 - 2s - loss: 0.0384 - accuracy: 0.9970 - val_loss: 17.0600 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.88444\n",
            "Epoch 22/50\n",
            "250/250 - 2s - loss: 0.0404 - accuracy: 0.9975 - val_loss: 25.7549 - val_accuracy: 0.8642\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.88444\n",
            "Epoch 23/50\n",
            "250/250 - 2s - loss: 0.0263 - accuracy: 0.9970 - val_loss: 25.2288 - val_accuracy: 0.8618\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.88444\n",
            "Epoch 24/50\n",
            "250/250 - 2s - loss: 0.0257 - accuracy: 0.9976 - val_loss: 34.3709 - val_accuracy: 0.8635\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88444\n",
            "Epoch 25/50\n",
            "250/250 - 2s - loss: 0.0720 - accuracy: 0.9971 - val_loss: 31.7468 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88444\n",
            "Epoch 26/50\n",
            "250/250 - 2s - loss: 0.0375 - accuracy: 0.9974 - val_loss: 25.7912 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88444\n",
            "Epoch 27/50\n",
            "250/250 - 2s - loss: 0.0526 - accuracy: 0.9976 - val_loss: 29.4581 - val_accuracy: 0.8599\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88444\n",
            "Epoch 28/50\n",
            "250/250 - 2s - loss: 0.0741 - accuracy: 0.9973 - val_loss: 21.6362 - val_accuracy: 0.8639\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88444\n",
            "Epoch 29/50\n",
            "250/250 - 2s - loss: 0.0347 - accuracy: 0.9976 - val_loss: 26.9168 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88444\n",
            "Epoch 30/50\n",
            "250/250 - 2s - loss: 0.0302 - accuracy: 0.9982 - val_loss: 33.2998 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88444\n",
            "Epoch 31/50\n",
            "250/250 - 2s - loss: 0.0508 - accuracy: 0.9973 - val_loss: 28.4397 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88444\n",
            "Epoch 32/50\n",
            "250/250 - 2s - loss: 0.0320 - accuracy: 0.9979 - val_loss: 35.2354 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88444\n",
            "Epoch 33/50\n",
            "250/250 - 2s - loss: 0.0346 - accuracy: 0.9984 - val_loss: 36.4758 - val_accuracy: 0.8623\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88444\n",
            "Epoch 34/50\n",
            "250/250 - 2s - loss: 0.0421 - accuracy: 0.9977 - val_loss: 31.6768 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88444\n",
            "Epoch 35/50\n",
            "250/250 - 2s - loss: 0.0309 - accuracy: 0.9984 - val_loss: 36.0625 - val_accuracy: 0.8615\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88444\n",
            "Epoch 36/50\n",
            "250/250 - 2s - loss: 0.0699 - accuracy: 0.9973 - val_loss: 25.9370 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88444\n",
            "Epoch 37/50\n",
            "250/250 - 2s - loss: 0.0424 - accuracy: 0.9976 - val_loss: 29.7820 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88444\n",
            "Epoch 38/50\n",
            "250/250 - 2s - loss: 0.0359 - accuracy: 0.9979 - val_loss: 24.4446 - val_accuracy: 0.8516\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88444\n",
            "Epoch 39/50\n",
            "250/250 - 2s - loss: 0.0265 - accuracy: 0.9985 - val_loss: 26.7893 - val_accuracy: 0.8623\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88444\n",
            "Epoch 40/50\n",
            "250/250 - 2s - loss: 0.0466 - accuracy: 0.9979 - val_loss: 32.5619 - val_accuracy: 0.8631\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88444\n",
            "Epoch 41/50\n",
            "250/250 - 2s - loss: 0.0704 - accuracy: 0.9972 - val_loss: 25.9902 - val_accuracy: 0.8619\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88444\n",
            "Epoch 42/50\n",
            "250/250 - 2s - loss: 0.0615 - accuracy: 0.9980 - val_loss: 36.1334 - val_accuracy: 0.8619\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88444\n",
            "Epoch 43/50\n",
            "250/250 - 2s - loss: 0.0751 - accuracy: 0.9969 - val_loss: 32.4050 - val_accuracy: 0.8605\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88444\n",
            "Epoch 44/50\n",
            "250/250 - 2s - loss: 0.1050 - accuracy: 0.9979 - val_loss: 19.2402 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88444\n",
            "Epoch 45/50\n",
            "250/250 - 2s - loss: 0.0488 - accuracy: 0.9976 - val_loss: 14.8056 - val_accuracy: 0.8616\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88444\n",
            "Epoch 46/50\n",
            "250/250 - 2s - loss: 0.0640 - accuracy: 0.9978 - val_loss: 28.5546 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88444\n",
            "Epoch 47/50\n",
            "250/250 - 2s - loss: 0.0456 - accuracy: 0.9979 - val_loss: 27.6466 - val_accuracy: 0.8618\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88444\n",
            "Epoch 48/50\n",
            "250/250 - 2s - loss: 0.0702 - accuracy: 0.9980 - val_loss: 25.5979 - val_accuracy: 0.8619\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88444\n",
            "Epoch 49/50\n",
            "250/250 - 2s - loss: 0.0462 - accuracy: 0.9968 - val_loss: 28.8236 - val_accuracy: 0.8639\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88444\n",
            "Epoch 50/50\n",
            "250/250 - 2s - loss: 0.0554 - accuracy: 0.9974 - val_loss: 23.0583 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88444\n",
            "RNN 0\n",
            "1\n",
            "104\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f493bcef780>\n",
            "Epoch 1/50\n",
            "250/250 - 406s - loss: 0.6806 - accuracy: 0.5520 - val_loss: 0.6332 - val_accuracy: 0.6241\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62412, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 2/50\n",
            "250/250 - 401s - loss: 0.5795 - accuracy: 0.6943 - val_loss: 0.4769 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.62412 to 0.77324, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 3/50\n",
            "250/250 - 401s - loss: 0.4574 - accuracy: 0.7956 - val_loss: 0.4638 - val_accuracy: 0.7880\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.77324 to 0.78796, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 4/50\n",
            "250/250 - 403s - loss: 0.3552 - accuracy: 0.8493 - val_loss: 0.3380 - val_accuracy: 0.8541\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.78796 to 0.85412, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 5/50\n",
            "250/250 - 405s - loss: 0.2830 - accuracy: 0.8842 - val_loss: 0.2938 - val_accuracy: 0.8755\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.85412 to 0.87552, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 6/50\n",
            "250/250 - 400s - loss: 0.2347 - accuracy: 0.9076 - val_loss: 0.3006 - val_accuracy: 0.8752\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.87552\n",
            "Epoch 7/50\n",
            "250/250 - 402s - loss: 0.2095 - accuracy: 0.9190 - val_loss: 0.2799 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.87552 to 0.88780, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 8/50\n",
            "250/250 - 402s - loss: 0.1839 - accuracy: 0.9316 - val_loss: 0.2649 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.88780 to 0.89356, saving model to weights\\weights_RNN_0.hdf5\n",
            "Epoch 9/50\n",
            "250/250 - 409s - loss: 0.1653 - accuracy: 0.9395 - val_loss: 0.2733 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89356\n",
            "Epoch 10/50\n",
            "250/250 - 403s - loss: 0.1472 - accuracy: 0.9464 - val_loss: 0.3084 - val_accuracy: 0.8866\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.89356\n",
            "Epoch 11/50\n",
            "250/250 - 403s - loss: 0.1346 - accuracy: 0.9510 - val_loss: 0.2921 - val_accuracy: 0.8900\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.89356\n",
            "Epoch 12/50\n",
            "250/250 - 402s - loss: 0.1198 - accuracy: 0.9585 - val_loss: 0.3090 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.89356\n",
            "Epoch 13/50\n",
            "250/250 - 397s - loss: 0.1077 - accuracy: 0.9618 - val_loss: 0.3503 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.89356\n",
            "Epoch 14/50\n",
            "250/250 - 397s - loss: 0.0970 - accuracy: 0.9663 - val_loss: 0.3699 - val_accuracy: 0.8783\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89356\n",
            "Epoch 15/50\n",
            "250/250 - 402s - loss: 0.0869 - accuracy: 0.9710 - val_loss: 0.3135 - val_accuracy: 0.8837\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89356\n",
            "Epoch 16/50\n",
            "250/250 - 399s - loss: 0.0763 - accuracy: 0.9744 - val_loss: 0.4183 - val_accuracy: 0.8841\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.89356\n",
            "Epoch 17/50\n",
            "250/250 - 398s - loss: 0.0645 - accuracy: 0.9793 - val_loss: 0.4635 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89356\n",
            "Epoch 18/50\n",
            "250/250 - 398s - loss: 0.0546 - accuracy: 0.9820 - val_loss: 0.5068 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89356\n",
            "Epoch 19/50\n",
            "250/250 - 398s - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.5712 - val_accuracy: 0.8796\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89356\n",
            "Epoch 20/50\n",
            "250/250 - 403s - loss: 0.0362 - accuracy: 0.9886 - val_loss: 0.5877 - val_accuracy: 0.8809\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89356\n",
            "Epoch 21/50\n",
            "250/250 - 414s - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.7516 - val_accuracy: 0.8779\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.89356\n",
            "Epoch 22/50\n",
            "250/250 - 399s - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.5530 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89356\n",
            "Epoch 23/50\n",
            "250/250 - 399s - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.9490 - val_accuracy: 0.8593\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89356\n",
            "Epoch 24/50\n",
            "250/250 - 407s - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.7138 - val_accuracy: 0.8749\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89356\n",
            "Epoch 25/50\n",
            "250/250 - 404s - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.9361 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89356\n",
            "Epoch 26/50\n",
            "250/250 - 402s - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.8279 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89356\n",
            "Epoch 27/50\n",
            "250/250 - 415s - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.8274 - val_accuracy: 0.8717\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89356\n",
            "Epoch 28/50\n",
            "250/250 - 417s - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.9863 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89356\n",
            "Epoch 29/50\n",
            "250/250 - 414s - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.9153 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89356\n",
            "Epoch 30/50\n",
            "250/250 - 408s - loss: 0.0078 - accuracy: 0.9980 - val_loss: 1.1162 - val_accuracy: 0.8700\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89356\n",
            "Epoch 31/50\n",
            "250/250 - 408s - loss: 0.0085 - accuracy: 0.9977 - val_loss: 1.0321 - val_accuracy: 0.8703\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89356\n",
            "Epoch 32/50\n",
            "250/250 - 409s - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.9985 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89356\n",
            "Epoch 33/50\n",
            "250/250 - 407s - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.0235 - val_accuracy: 0.8722\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89356\n",
            "Epoch 34/50\n",
            "250/250 - 410s - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.2039 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89356\n",
            "Epoch 35/50\n",
            "250/250 - 403s - loss: 0.0058 - accuracy: 0.9986 - val_loss: 1.0552 - val_accuracy: 0.8731\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89356\n",
            "Epoch 36/50\n",
            "250/250 - 414s - loss: 0.0065 - accuracy: 0.9984 - val_loss: 1.0501 - val_accuracy: 0.8707\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89356\n",
            "Epoch 37/50\n",
            "250/250 - 411s - loss: 0.0059 - accuracy: 0.9986 - val_loss: 1.1390 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89356\n",
            "Epoch 38/50\n",
            "250/250 - 398s - loss: 0.0063 - accuracy: 0.9987 - val_loss: 1.2410 - val_accuracy: 0.8711\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89356\n",
            "Epoch 39/50\n",
            "250/250 - 417s - loss: 0.0054 - accuracy: 0.9987 - val_loss: 1.4309 - val_accuracy: 0.8701\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89356\n",
            "Epoch 40/50\n",
            "250/250 - 419s - loss: 0.0044 - accuracy: 0.9992 - val_loss: 1.6424 - val_accuracy: 0.8694\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89356\n",
            "Epoch 41/50\n",
            "250/250 - 410s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 1.6896 - val_accuracy: 0.8734\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89356\n",
            "Epoch 42/50\n",
            "250/250 - 408s - loss: 0.0058 - accuracy: 0.9985 - val_loss: 1.2357 - val_accuracy: 0.8705\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89356\n",
            "Epoch 43/50\n",
            "250/250 - 407s - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.3622 - val_accuracy: 0.8724\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89356\n",
            "Epoch 44/50\n",
            "250/250 - 422s - loss: 0.0028 - accuracy: 0.9993 - val_loss: 1.8416 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89356\n",
            "Epoch 45/50\n",
            "250/250 - 410s - loss: 0.0047 - accuracy: 0.9991 - val_loss: 1.5045 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89356\n",
            "Epoch 46/50\n",
            "250/250 - 408s - loss: 0.0045 - accuracy: 0.9991 - val_loss: 1.3984 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89356\n",
            "Epoch 47/50\n",
            "250/250 - 414s - loss: 0.0042 - accuracy: 0.9988 - val_loss: 1.7757 - val_accuracy: 0.8637\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89356\n",
            "Epoch 48/50\n",
            "250/250 - 419s - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.4701 - val_accuracy: 0.8666\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89356\n",
            "Epoch 49/50\n",
            "250/250 - 416s - loss: 0.0048 - accuracy: 0.9989 - val_loss: 1.2994 - val_accuracy: 0.8685\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89356\n",
            "Epoch 50/50\n",
            "250/250 - 419s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 2.2717 - val_accuracy: 0.8700\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89356\n",
            "RNN 1\n",
            "4\n",
            "85\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f493d4924e0>\n",
            "Epoch 1/50\n",
            "250/250 - 1045s - loss: 0.6902 - accuracy: 0.5304 - val_loss: 0.6508 - val_accuracy: 0.6149\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61488, saving model to weights\\weights_RNN_1.hdf5\n",
            "Epoch 2/50\n",
            "250/250 - 1009s - loss: 0.6058 - accuracy: 0.6798 - val_loss: 0.5460 - val_accuracy: 0.7599\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.61488 to 0.75988, saving model to weights\\weights_RNN_1.hdf5\n",
            "Epoch 3/50\n",
            "250/250 - 1018s - loss: 0.4767 - accuracy: 0.7868 - val_loss: 0.4286 - val_accuracy: 0.8365\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.75988 to 0.83648, saving model to weights\\weights_RNN_1.hdf5\n",
            "Epoch 4/50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}