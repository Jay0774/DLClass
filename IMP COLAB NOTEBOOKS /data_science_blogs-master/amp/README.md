Do you know that the Backpropagation algorithm was given in 1986 in the Nature paper by Geoffrey Hinton?

Also, the Convnets were first presented by Yann le cun in 1998 for digit classification where he used a single convolution layer. It was only later in 2012 that Alexnet popularized Convnets by using multiple convolution layers to achieve state of the art on imagenet.
So what made them so famous just now and not before?

It is only with the vast computing resources at our disposal, were we able to experiment and utilize Deep Learning to its full potential in the recent past.

But are we using our computing resources well enough? Can we do better?
This post is about utilizing Tensor Cores and Automatic Mixed Precision for faster training of Deep Learning Networks.

[Read More](https://towardsdatascience.com/faster-and-memory-efficient-pytorch-models-using-amp-50fd3c8dd7fe)