{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Tensor Using torch.Tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [3., 4., 5.]])\n",
      "Created Tensor Using torch.randn:\n",
      "tensor([[-0.3058,  0.4658,  0.9589, -1.1946,  0.0468],\n",
      "        [ 1.1972,  0.4946, -0.7867,  0.3801, -0.1841],\n",
      "        [-0.4104,  1.7376, -0.3540,  0.5128,  1.1579]])\n",
      "Created Tensor Using torch.ones:\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "Created Tensor Using torch.zeros:\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Created Tensor Using torch.randint:\n",
      "tensor([[1, 2, 9, 5, 7],\n",
      "        [0, 3, 2, 4, 0],\n",
      "        [9, 1, 7, 2, 7],\n",
      "        [3, 2, 0, 4, 0]])\n",
      "Convert to Tensor From Numpy Array:\n",
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n",
      "Convert to Numpy Array From Tensor:\n",
      "[[1 2 3]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "# Using torch.Tensor\n",
    "t = torch.Tensor([[1,2,3],[3,4,5]])\n",
    "print(f\"Created Tensor Using torch.Tensor:\\n{t}\")\n",
    "\n",
    "# Using torch.randn\n",
    "t = torch.randn(3, 5)\n",
    "print(f\"Created Tensor Using torch.randn:\\n{t}\")\n",
    "\n",
    "# using torch.[ones|zeros](*size)\n",
    "t = torch.ones(3, 5)\n",
    "print(f\"Created Tensor Using torch.ones:\\n{t}\")\n",
    "t = torch.zeros(3, 5)\n",
    "print(f\"Created Tensor Using torch.zeros:\\n{t}\")\n",
    "\n",
    "# using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded) \n",
    "t = torch.randint(low = 0,high = 10,size = (4,5))\n",
    "print(f\"Created Tensor Using torch.randint:\\n{t}\")\n",
    "\n",
    "# Using from_numpy to convert from Numpy Array to Tensor \n",
    "a = np.array([[1,2,3],[3,4,5]])\n",
    "t = torch.from_numpy(a)\n",
    "print(f\"Convert to Tensor From Numpy Array:\\n{t}\")\n",
    "\n",
    "# Using .numpy() to convert from Tensor to Numpy array \n",
    "t = t.numpy()\n",
    "print(f\"Convert to Numpy Array From Tensor:\\n{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Tensor t by Multiplying A and W:\n",
      "tensor([[ 2.6782,  0.6292],\n",
      "        [ 0.9754, -2.8601],\n",
      "        [ 0.4682,  1.7653]])\n",
      "Transpose of Tensor t:\n",
      "tensor([[ 2.6782,  0.9754,  0.4682],\n",
      "        [ 0.6292, -2.8601,  1.7653]])\n",
      "Square each element of Tensor t:\n",
      "tensor([[7.1728, 0.9514, 0.2192],\n",
      "        [0.3959, 8.1800, 3.1161]])\n",
      "Size of Tensor t using .size():\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "W = torch.randn(4,2)\n",
    "# Multiply Matrix A and W\n",
    "t = A.mm(W)\n",
    "print(f\"Created Tensor t by Multiplying A and W:\\n{t}\")\n",
    "# Transpose Tensor t\n",
    "t = t.t()\n",
    "print(f\"Transpose of Tensor t:\\n{t}\")\n",
    "# Square each element of t\n",
    "t = t**2\n",
    "print(f\"Square each element of Tensor t:\\n{t}\")\n",
    "# return the size of a tensor\n",
    "print(f\"Size of Tensor t using .size():\\n{t.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define all Layers Here\n",
    "        self.lin1 = nn.Linear(784, 30)\n",
    "        self.lin2 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Connect the layer Outputs here to define the forward pass\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((100,784))\n",
    "model = myNeuralNet()\n",
    "model(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCrazyNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define all Layers Here\n",
    "        self.lin1 = nn.Linear(784, 30)\n",
    "        self.lin2 = nn.Linear(30, 784)\n",
    "        self.lin3 = nn.Linear(30, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Connect the layer Outputs here to define the forward pass\n",
    "        x_lin1 = self.lin1(x)\n",
    "        x_lin2 = x + self.lin2(x_lin1)\n",
    "        x_lin2 = self.lin1(x_lin2)\n",
    "        x = self.lin3(x_lin2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((100,784))\n",
    "model = myCrazyNeuralNet()\n",
    "model(x).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A word aboutÂ Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class myCustomLinearLayer(nn.Module):\n",
    "    def __init__(self,in_size,out_size):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(in_size, out_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.mm(self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCustomNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define all Layers Here\n",
    "        self.lin1 = myCustomLinearLayer(784,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Connect the layer Outputs here to define the forward pass\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((100,784))\n",
    "model = myCustomNeuralNet()\n",
    "model(x).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2d Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = (3,3), stride = 1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 24, 24])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((100,3,24,24))\n",
    "conv_layer(x).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = \"/home/rahul/projects/compvisblog/data/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Images in Dataset: 847\n",
      "Example Image and Label: (tensor([[[0.1882, 0.2118, 0.2118,  ..., 0.1686, 0.1569, 0.1725],\n",
      "         [0.1882, 0.2039, 0.2275,  ..., 0.1882, 0.1765, 0.1961],\n",
      "         [0.1725, 0.1529, 0.1843,  ..., 0.1020, 0.1176, 0.1569],\n",
      "         ...,\n",
      "         [0.1451, 0.1412, 0.1333,  ..., 0.1176, 0.1137, 0.1059],\n",
      "         [0.1255, 0.1216, 0.1137,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.1333, 0.1294, 0.1255,  ..., 0.0980, 0.0980, 0.0941]],\n",
      "\n",
      "        [[0.4784, 0.4902, 0.4863,  ..., 0.4941, 0.4902, 0.4980],\n",
      "         [0.4980, 0.5020, 0.5216,  ..., 0.4941, 0.4824, 0.5020],\n",
      "         [0.5020, 0.4863, 0.5098,  ..., 0.4549, 0.4588, 0.4902],\n",
      "         ...,\n",
      "         [0.4588, 0.4549, 0.4471,  ..., 0.4078, 0.4000, 0.3922],\n",
      "         [0.4353, 0.4314, 0.4275,  ..., 0.3961, 0.3843, 0.3804],\n",
      "         [0.4431, 0.4353, 0.4314,  ..., 0.3961, 0.3882, 0.3843]],\n",
      "\n",
      "        [[0.8157, 0.8235, 0.8118,  ..., 0.8314, 0.8314, 0.8784],\n",
      "         [0.8627, 0.8627, 0.8706,  ..., 0.8118, 0.8118, 0.8471],\n",
      "         [0.8667, 0.8353, 0.8667,  ..., 0.7922, 0.8000, 0.8431],\n",
      "         ...,\n",
      "         [0.7451, 0.7451, 0.7373,  ..., 0.7333, 0.7216, 0.7059],\n",
      "         [0.7216, 0.7176, 0.7098,  ..., 0.7020, 0.7020, 0.6941],\n",
      "         [0.7373, 0.7294, 0.7294,  ..., 0.7020, 0.6902, 0.6824]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "t = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=traindir,transform=t)\n",
    "\n",
    "print(\"Num Images in Dataset:\", len(train_dataset))\n",
    "print(\"Example Image and Label:\", train_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6157, 0.6196, 0.6118,  ..., 0.6157, 0.6157, 0.6118],\n",
      "         [0.6392, 0.6275, 0.6118,  ..., 0.6275, 0.6314, 0.6353],\n",
      "         [0.6353, 0.6157, 0.6078,  ..., 0.6431, 0.6431, 0.6588],\n",
      "         ...,\n",
      "         [0.6980, 0.6706, 0.6431,  ..., 0.5333, 0.5686, 0.5882],\n",
      "         [0.6863, 0.6275, 0.6235,  ..., 0.6196, 0.6039, 0.6039],\n",
      "         [0.6118, 0.5490, 0.5922,  ..., 0.6039, 0.6196, 0.5647]],\n",
      "\n",
      "        [[0.7098, 0.7098, 0.7059,  ..., 0.7059, 0.7098, 0.7059],\n",
      "         [0.7255, 0.7098, 0.7020,  ..., 0.7137, 0.7176, 0.7216],\n",
      "         [0.7137, 0.7020, 0.6980,  ..., 0.7216, 0.7255, 0.7333],\n",
      "         ...,\n",
      "         [0.7255, 0.7059, 0.6627,  ..., 0.5686, 0.5961, 0.6235],\n",
      "         [0.7137, 0.6627, 0.6588,  ..., 0.6549, 0.6353, 0.6314],\n",
      "         [0.6353, 0.5804, 0.6314,  ..., 0.6431, 0.6510, 0.5922]],\n",
      "\n",
      "        [[0.8196, 0.8275, 0.8275,  ..., 0.8196, 0.8196, 0.8157],\n",
      "         [0.8275, 0.8235, 0.8157,  ..., 0.8196, 0.8235, 0.8275],\n",
      "         [0.8157, 0.8196, 0.8196,  ..., 0.8314, 0.8275, 0.8275],\n",
      "         ...,\n",
      "         [0.7608, 0.7255, 0.6902,  ..., 0.5961, 0.6275, 0.6510],\n",
      "         [0.7451, 0.6941, 0.6863,  ..., 0.6824, 0.6627, 0.6706],\n",
      "         [0.6706, 0.6039, 0.6471,  ..., 0.6784, 0.6863, 0.6275]]]) 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(train_dataset)):\n",
    "    image ,label = train_dataset[i]\n",
    "    print(image,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size = 64, shuffle=True, num_workers=10)\n",
    "for image_batch, label_batch in train_dataloader:\n",
    "    print(image_batch.size(),label_batch.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=traindir,transform=t)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size = 64, shuffle=True, num_workers=10)\n",
    "\n",
    "for image_batch, label_batch in train_dataloader:\n",
    "    pred = myImageNeuralNet(img_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class customImageFolderDataset(Dataset):\n",
    "    \"\"\"Custom Image Loader dataset.\"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (string): Path to the images organized in a particular folder structure.\n",
    "            transform: Any Pytorch transform to be applied\n",
    "        \"\"\"\n",
    "        # Get all image paths from a directory\n",
    "        self.image_paths = glob(f\"{root}/*/*\")\n",
    "        # Get the labels from the image paths\n",
    "        self.labels = [x.split(\"/\")[-2] for x in self.image_paths]\n",
    "        # Create a dictionary mapping each label to a index from 0 to len(classes).\n",
    "        self.label_to_idx = {x:i for i,x in enumerate(set(self.labels))}\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return length of dataset\n",
    "        return len(self.image_paths)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        # open and send one image and label\n",
    "        img_name = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,self.label_to_idx[label]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "train_dataset = customImageFolderDataset(root=traindir,transform=t)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size = 64, shuffle=True, num_workers=10)\n",
    "\n",
    "for image_batch, label_batch in train_dataloader:\n",
    "    #print(image_batch)\n",
    "    pred = myImageNeuralNet(img_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 64\n",
    "        drp = 0.1\n",
    "        max_features, embed_size = 10000,300\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size*4 , 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
    "        \n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        avg_pool = torch.mean(h_lstm, 1)\n",
    "        max_pool, _ = torch.max(h_lstm, 1)\n",
    "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        out = self.out(conc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM()\n",
    "input_batch_1 = torch.randint(low = 0,high = 10000, size = (100,10))\n",
    "input_batch_2 = torch.randint(low = 0,high = 10000, size = (100,25))\n",
    "print(model(input_batch_1).size())\n",
    "print(model(input_batch_2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextDataset(Dataset):\n",
    "    '''\n",
    "    Simple Dataset initializes with X and y vectors\n",
    "    We start by sorting our X and y vectors by sequence lengths\n",
    "    '''\n",
    "    def __init__(self,X,y=None):\n",
    "        self.data = list(zip(X,y))\n",
    "        # Sort by length of first element in tuple\n",
    "        self.data = sorted(self.data, key=lambda x: len(x[0]))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data_size = 1024\n",
    "sizes = np.random.randint(low=50,high=300,size=(train_data_size,))\n",
    "\n",
    "X = [np.random.randint(0,10000, (sizes[i])) for i in range(train_data_size)]\n",
    "y = np.random.rand(train_data_size).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 167, 3822, 4885,  246, 6351, 3738, 4192, 6041, 8267,  238, 8960,\n",
      "       9112, 8563, 4342, 6757, 4193, 4188, 8421, 1942, 8743, 3062, 8293,\n",
      "       5065, 1461, 5614, 8068, 7612, 2164, 7469, 5242, 4299, 5794, 9966,\n",
      "       3385, 7728, 8258, 2627, 1376, 5062, 1986, 1505, 2140, 4468, 3175,\n",
      "       5517, 5646, 6707, 6097, 7448, 9749, 3755, 4422, 3349, 9645, 4058,\n",
      "       6967, 9123, 1997, 1939, 6086, 9079, 4669, 2787, 9958, 7377,  252,\n",
      "       9239, 6900, 8168, 9174, 8561, 3745, 5906, 1761, 1425, 7515, 7478,\n",
      "       2004, 9641, 8321, 3508, 1280, 7079, 2780, 3423,  974, 4520, 7069,\n",
      "       9194, 2634, 8392, 1912, 2015, 1260, 7777, 6938, 1254, 2778, 5904,\n",
      "       5485, 5106, 9698, 6013, 4624, 1251, 3259, 3732, 3518, 3740, 3589,\n",
      "       6537, 9744, 4021, 1980, 6451, 7411, 2977, 6496, 3492, 7167, 2686,\n",
      "       2677, 6791, 1186, 3977, 2770, 5897, 2208, 6885, 5450,  677, 3481,\n",
      "       5563, 9767, 7090, 8707, 2419, 2022, 7519, 5979, 8901, 4643, 1795,\n",
      "       3213, 3721, 5854,  405, 6209, 3998, 6707, 1741, 5903, 7300, 3097,\n",
      "       2730, 8569, 8472, 6080, 6943, 9151, 6115,  518, 9018, 6380, 9199,\n",
      "        198]), 1.0)\n"
     ]
    }
   ],
   "source": [
    "print((X[0],y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now use a simple Dataloader on top of this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomTextDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size = 64, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 64, in default_collate\n    return default_collate([torch.as_tensor(b) for b in batch])\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [50] at entry 0 and [51] at entry 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-16d5618463b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 64, in default_collate\n    return default_collate([torch.as_tensor(b) for b in batch])\n  File \"/home/rahul/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [50] at entry 0 and [51] at entry 2\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_dataloader:\n",
    "    print(xb.size(),yb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_text(batch):\n",
    "    # get text sequences in batch\n",
    "    data = [item[0] for item in batch]\n",
    "    # get labels in batch\n",
    "    target = [item[1] for item in batch]\n",
    "    # get max_seq_length in batch\n",
    "    max_seq_len = max([len(x) for x in data])\n",
    "    # pad text sequences based on max_seq_len\n",
    "    data = [np.pad(p, (0, max_seq_len - len(p)), 'constant') for p in data]\n",
    "    # convert data and target to tensor\n",
    "    data = torch.LongTensor(data)\n",
    "    target = torch.LongTensor(target)\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 66]) torch.Size([64])\n",
      "torch.Size([64, 84]) torch.Size([64])\n",
      "torch.Size([64, 98]) torch.Size([64])\n",
      "torch.Size([64, 110]) torch.Size([64])\n",
      "torch.Size([64, 126]) torch.Size([64])\n",
      "torch.Size([64, 141]) torch.Size([64])\n",
      "torch.Size([64, 158]) torch.Size([64])\n",
      "torch.Size([64, 173]) torch.Size([64])\n",
      "torch.Size([64, 190]) torch.Size([64])\n",
      "torch.Size([64, 204]) torch.Size([64])\n",
      "torch.Size([64, 222]) torch.Size([64])\n",
      "torch.Size([64, 240]) torch.Size([64])\n",
      "torch.Size([64, 255]) torch.Size([64])\n",
      "torch.Size([64, 270]) torch.Size([64])\n",
      "torch.Size([64, 287]) torch.Size([64])\n",
      "torch.Size([64, 299]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size = 64, shuffle=False, \n",
    "                              num_workers=10,collate_fn = collate_text)\n",
    "for xb,yb in train_dataloader:\n",
    "    print(xb.size(),yb.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network training code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    for x_batch,y_batch in train_dataloader:\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass - Predicted outputs\n",
    "        pred = model(x_batch)\n",
    "        # Find Loss and backpropagation of gradients\n",
    "        loss = loss_criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    for x_batch,y_batch in valid_dataloader:\n",
    "        pred = model(x_batch)\n",
    "        val_loss = loss_criterion(pred, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define all Layers Here\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Connect the layer Outputs here to define the forward pass\n",
    "        x = self.lin(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some random input:\n",
    "\n",
    "X = torch.randn(100,784)\n",
    "y = torch.randint(low = 0,high = 10,size = (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myClassificationNet()\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "loss = criterion(preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4242, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse_loss(output,target):\n",
    "    loss = torch.mean((output - target)**2)     \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output = model(x)\n",
    "loss = custom_mse_loss(output, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "pytorchNLLloss = criterion(preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomNLLLossFunc(x, y):\n",
    "    log_prob = -1.0 * x\n",
    "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomNLLLossFuncLoss = CustomNLLLossFunc(preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNLLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x, y):\n",
    "        # x should be output from LogSoftmax Layer \n",
    "        log_prob = -1.0 * x\n",
    "        # Get log_prob based on y class_index as loss=-mean(ylogp)\n",
    "        loss = log_prob.gather(1, y.unsqueeze(1))\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CustomNLLLoss()\n",
    "CustomNLLLossClass = criterion(preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorchNLLloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomNLLLossFuncLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomNLLLossClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for x_batch,y_batch in train_dataloader:\n",
    "        if train_on_gpu:\n",
    "            x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    for x_batch,y_batch in valid_dataloader:\n",
    "        if train_on_gpu:\n",
    "            x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        pred = model(x_batch)\n",
    "        val_loss = loss_criterion(pred, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "pyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
