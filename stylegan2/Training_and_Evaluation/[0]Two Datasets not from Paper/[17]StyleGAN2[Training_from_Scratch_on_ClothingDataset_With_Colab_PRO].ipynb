{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[17]StyleGAN2[Training_from_Scratch_on_ClothingDataset_With_Colab_PRO].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHRa7f3XYcFw"
      },
      "source": [
        "From the continution to FILE: [14]StyleGAN2[Training_on_Clothing_Dataset_Without_Colab_Pro].ipynb\n",
        "\n",
        "\n",
        "FACT: This work is completely Noevl. Till the date trained models are available here: https://github.com/justinpinkney/awesome-pretrained-stylegan2\n",
        "\n",
        "This work will add new model for Clothing GANs. Additionally, I will be releasing this for public domain as .pkl file as well. \n",
        "\n",
        "(Thanks to Colab Pro for training this awesome network for me! with exchange of $10 ðŸ˜›)\n",
        "\n",
        "GANs are beautiful!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIgEevpPUTWD",
        "outputId": "a146f0c7-b359-4f88-bf5c-1a2857038452"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install opensimplex\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/stylegan2\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting opensimplex\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/ad/9b758f9ff9dcd23fc574bb3aa1de844adb1179c9be9711e9f798614d4b2f/opensimplex-0.3-py3-none-any.whl\n",
            "Installing collected packages: opensimplex\n",
            "Successfully installed opensimplex-0.3\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/stylegan2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFnk_XGzqjK7"
      },
      "source": [
        "# # Dont run this if you already have this clothing dataset file of 7GB in drive.\n",
        "# api_token = {\"username\":\"samy280497\",\"key\":\"f80239517ec84712358a021a2389ffc4\"}\n",
        "# !mkdir ~/.kaggle\n",
        "# !touch ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "# import json\n",
        "\n",
        "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "#     json.dump(api_token, file)\n",
        "\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d agrigorev/clothing-dataset-full\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oOUWVPiqtMv"
      },
      "source": [
        "# !unzip clothing-dataset-full.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPKHu8ZsX4qs",
        "outputId": "804df0e4-a34e-4da0-e357-125ff689da15"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clothing-dataset-full.zip  images.csv\t    stylegan2\n",
            "images_compressed\t   images_original\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skUcv40PY3tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f5f3bb-fc28-4a2b-cc40-49ab4888e37e"
      },
      "source": [
        "# Dont run this if you have already converted images\n",
        "%cd \"/content/drive/My Drive/stylegan2/images_original\"\n",
        "#!/usr/bin/python\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "path = \"/content/drive/My Drive/stylegan2/images_original/\"\n",
        "dirs = os.listdir(path)\n",
        "\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            im = im.convert('RGB')\n",
        "            f, e = os.path.splitext(path+item)\n",
        "            imResize = im.resize((1024,1024), Image.ANTIALIAS)\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "resize()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/stylegan2/images_original\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SQB3Ehjax8f",
        "outputId": "28222bf3-b43b-4403-8591-1dc6c8f46edc"
      },
      "source": [
        "%cd \"/content/drive/My Drive/stylegan2/stylegan2/\"\n",
        "#2nd argument is where to put your tfrecords files\n",
        "#3rd should point at your image dataset\n",
        "!python dataset_tool.py create_from_images /content/drive/My\\ Drive/stylegan2/stylegan2/datasets/images_original /content/drive/My\\ Drive/stylegan2/images_original"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/stylegan2/stylegan2\n",
            "Loading images from \"/content/drive/My Drive/stylegan2/images_original\"\n",
            "100% 5762/5762 [30:27<00:00,  3.15it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6Xl5156a9_v",
        "outputId": "7fb0a2ee-636c-4a6d-b9f3-fcadacf4f6ba"
      },
      "source": [
        "%cd \"/content/drive/My Drive/stylegan2/stylegan2/datasets/images_original/\"\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/stylegan2/stylegan2/datasets/images_original\n",
            "images_original-r02.tfrecords  images_original-r07.tfrecords\n",
            "images_original-r03.tfrecords  images_original-r08.tfrecords\n",
            "images_original-r04.tfrecords  images_original-r09.tfrecords\n",
            "images_original-r05.tfrecords  images_original-r10.tfrecords\n",
            "images_original-r06.tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2mM57fqO9_c"
      },
      "source": [
        "When you put metrics == None it starts with some baseline model which is a kind of transfer learning. The baseline model has features very generic, just like the early layers learn to represent edges and later layers represnt class specific designs. This is why training is starting from kimg=10000th iteration, However author has mentioned that it is equivalent to say it as training from scratch. There is one more reason that you can call it as training from scratch because the early features even after the kimg == 100000th it does not show any sign of the dataset from which it was trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yHdqQNucGGJ",
        "outputId": "6fe05c46-0c22-4030-f2b2-c5c8178722c3"
      },
      "source": [
        "%cd \"/content/drive/My Drive/stylegan2/stylegan2/\"\n",
        "!python run_training.py --num-gpus=1 --data-dir=./datasets --config=config-f --dataset=images_original --mirror-augment=true --metrics=wid50k\n",
        "# Running metrics doesnt actually matter a lot as we will going to calculate the metrics fid50k standalone below cells as well.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/stylegan2/stylegan2\n",
            "Couldn't find valid snapshot, starting over\n",
            "Local submit - run_dir: results/00000-stylegan2-images_original-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7c52000 @  0x7ffb7d418001 0x7ffb79ebe4ff 0x7ffb79f0eb08 0x7ffb79f12ac7 0x7ffb79fb11a3 0x50a4a5 0x50cc96 0x507be4 0x508ec2 0x594a01 0x549e8f 0x5515c1 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x588e5c 0x59fd0e\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7ff98fac6000 @  0x7ffb7d4161e7 0x7ffb79ebe41e 0x7ffb79f0ec2b 0x7ffb79f0f30f 0x7ffb79fb10a3 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7ff88eac4000 @  0x7ffb7d4161e7 0x7ffb79ebe41e 0x7ffb79f0ec2b 0x7ffb79f0f30f 0x7ffb2341f0c5 0x7ffb22da2902 0x7ffb22da2eb2 0x7ffb22d5bc3e 0x50a12f 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x588c8b 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x594a01\n",
            "Dataset shape = [3, 1024, 1024]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "\n",
            "G                               Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "lod                             -         ()                   -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "G_mapping/latents_in            -         (?, 512)             -               \n",
            "G_mapping/labels_in             -         (?, 0)               -               \n",
            "G_mapping/Normalize             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "G_mapping/dlatents_out          -         (?, 18, 512)         -               \n",
            "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
            "G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
            "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
            "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
            "G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise1              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise3              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise5              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise7              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise9              -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise11             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise13             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise15             -         (1, 1, 1024, 1024)   -               \n",
            "G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n",
            "images_out                      -         (?, 3, 1024, 1024)   -               \n",
            "---                             ---       ---                  ---             \n",
            "Total                           30370060                                       \n",
            "\n",
            "\n",
            "D                     Params    OutputShape          WeightShape     \n",
            "---                   ---       ---                  ---             \n",
            "images_in             -         (?, 3, 1024, 1024)   -               \n",
            "labels_in             -         (?, 0)               -               \n",
            "1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n",
            "1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n",
            "1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n",
            "512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n",
            "512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n",
            "256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n",
            "256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n",
            "128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n",
            "128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n",
            "64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n",
            "32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n",
            "16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n",
            "8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n",
            "4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n",
            "4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n",
            "Output                513       (?, 1)               (512, 1)        \n",
            "scores_out            -         (?, 1)               -               \n",
            "---                   ---       ---                  ---             \n",
            "Total                 29012513                                       \n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 10000.1  lod 0.00  minibatch 32   time 1m 53s       sec/tick 113.3   sec/kimg 885.49  maintenance 0.0    gpumem 8.6\n",
            "tick 1     kimg 10004.2  lod 0.00  minibatch 32   time 16m 11s      sec/tick 825.6   sec/kimg 201.55  maintenance 31.7   gpumem 8.6\n",
            "tick 2     kimg 10008.3  lod 0.00  minibatch 32   time 30m 08s      sec/tick 827.0   sec/kimg 201.91  maintenance 10.3   gpumem 8.6\n",
            "tick 3     kimg 10012.4  lod 0.00  minibatch 32   time 44m 05s      sec/tick 826.8   sec/kimg 201.86  maintenance 10.5   gpumem 8.6\n",
            "tick 4     kimg 10016.5  lod 0.00  minibatch 32   time 58m 02s      sec/tick 826.5   sec/kimg 201.77  maintenance 10.5   gpumem 8.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoxJDnIdWApb"
      },
      "source": [
        "# **I had to stop this training process because it took longer than expected to even show some results. The results were not looking as expected. Even after 1 hour of training. Have to start from scratch rather than using transfer learning.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR2vdK4hWUAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}